{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd6afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70cb48b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\DELL\\Documents\\Advanced topics\\Parkinsson disease.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e94cbf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>phon_R01_S50_2</td>\n",
       "      <td>174.188</td>\n",
       "      <td>230.978</td>\n",
       "      <td>94.261</td>\n",
       "      <td>0.00459</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00263</td>\n",
       "      <td>0.00259</td>\n",
       "      <td>0.00790</td>\n",
       "      <td>0.04087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07008</td>\n",
       "      <td>0.02764</td>\n",
       "      <td>19.517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.448439</td>\n",
       "      <td>0.657899</td>\n",
       "      <td>-6.538586</td>\n",
       "      <td>0.121952</td>\n",
       "      <td>2.657476</td>\n",
       "      <td>0.133050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>phon_R01_S50_3</td>\n",
       "      <td>209.516</td>\n",
       "      <td>253.017</td>\n",
       "      <td>89.488</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00331</td>\n",
       "      <td>0.00292</td>\n",
       "      <td>0.00994</td>\n",
       "      <td>0.02751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04812</td>\n",
       "      <td>0.01810</td>\n",
       "      <td>19.147</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431674</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>-6.195325</td>\n",
       "      <td>0.129303</td>\n",
       "      <td>2.784312</td>\n",
       "      <td>0.168895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>phon_R01_S50_4</td>\n",
       "      <td>174.688</td>\n",
       "      <td>240.005</td>\n",
       "      <td>74.287</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00624</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.01873</td>\n",
       "      <td>0.02308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03804</td>\n",
       "      <td>0.10715</td>\n",
       "      <td>17.883</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407567</td>\n",
       "      <td>0.655683</td>\n",
       "      <td>-6.787197</td>\n",
       "      <td>0.158453</td>\n",
       "      <td>2.679772</td>\n",
       "      <td>0.131728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>phon_R01_S50_5</td>\n",
       "      <td>198.764</td>\n",
       "      <td>396.961</td>\n",
       "      <td>74.904</td>\n",
       "      <td>0.00740</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00390</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.02296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03794</td>\n",
       "      <td>0.07223</td>\n",
       "      <td>19.020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.451221</td>\n",
       "      <td>0.643956</td>\n",
       "      <td>-6.744577</td>\n",
       "      <td>0.207454</td>\n",
       "      <td>2.138608</td>\n",
       "      <td>0.123306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>phon_R01_S50_6</td>\n",
       "      <td>214.289</td>\n",
       "      <td>260.277</td>\n",
       "      <td>77.973</td>\n",
       "      <td>0.00567</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.00317</td>\n",
       "      <td>0.00885</td>\n",
       "      <td>0.01884</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03078</td>\n",
       "      <td>0.04398</td>\n",
       "      <td>21.209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.462803</td>\n",
       "      <td>0.664357</td>\n",
       "      <td>-5.724056</td>\n",
       "      <td>0.190667</td>\n",
       "      <td>2.555477</td>\n",
       "      <td>0.148569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0    phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1    phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2    phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3    phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4    phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "..              ...          ...           ...           ...             ...   \n",
       "190  phon_R01_S50_2      174.188       230.978        94.261         0.00459   \n",
       "191  phon_R01_S50_3      209.516       253.017        89.488         0.00564   \n",
       "192  phon_R01_S50_4      174.688       240.005        74.287         0.01360   \n",
       "193  phon_R01_S50_5      198.764       396.961        74.904         0.00740   \n",
       "194  phon_R01_S50_6      214.289       260.277        77.973         0.00567   \n",
       "\n",
       "     MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0             0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1             0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2             0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3             0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4             0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "..                ...       ...       ...         ...           ...  ...   \n",
       "190           0.00003   0.00263   0.00259     0.00790       0.04087  ...   \n",
       "191           0.00003   0.00331   0.00292     0.00994       0.02751  ...   \n",
       "192           0.00008   0.00624   0.00564     0.01873       0.02308  ...   \n",
       "193           0.00004   0.00370   0.00390     0.01109       0.02296  ...   \n",
       "194           0.00003   0.00295   0.00317     0.00885       0.01884  ...   \n",
       "\n",
       "     Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0        0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1        0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2        0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3        0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4        0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "..           ...      ...     ...     ...       ...       ...       ...   \n",
       "190      0.07008  0.02764  19.517       0  0.448439  0.657899 -6.538586   \n",
       "191      0.04812  0.01810  19.147       0  0.431674  0.683244 -6.195325   \n",
       "192      0.03804  0.10715  17.883       0  0.407567  0.655683 -6.787197   \n",
       "193      0.03794  0.07223  19.020       0  0.451221  0.643956 -6.744577   \n",
       "194      0.03078  0.04398  21.209       0  0.462803  0.664357 -5.724056   \n",
       "\n",
       "      spread2        D2       PPE  \n",
       "0    0.266482  2.301442  0.284654  \n",
       "1    0.335590  2.486855  0.368674  \n",
       "2    0.311173  2.342259  0.332634  \n",
       "3    0.334147  2.405554  0.368975  \n",
       "4    0.234513  2.332180  0.410335  \n",
       "..        ...       ...       ...  \n",
       "190  0.121952  2.657476  0.133050  \n",
       "191  0.129303  2.784312  0.168895  \n",
       "192  0.158453  2.679772  0.131728  \n",
       "193  0.207454  2.138608  0.123306  \n",
       "194  0.190667  2.555477  0.148569  \n",
       "\n",
       "[195 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the dataset\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8099ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195 entries, 0 to 194\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              195 non-null    object \n",
      " 1   MDVP:Fo(Hz)       195 non-null    float64\n",
      " 2   MDVP:Fhi(Hz)      195 non-null    float64\n",
      " 3   MDVP:Flo(Hz)      195 non-null    float64\n",
      " 4   MDVP:Jitter(%)    195 non-null    float64\n",
      " 5   MDVP:Jitter(Abs)  195 non-null    float64\n",
      " 6   MDVP:RAP          195 non-null    float64\n",
      " 7   MDVP:PPQ          195 non-null    float64\n",
      " 8   Jitter:DDP        195 non-null    float64\n",
      " 9   MDVP:Shimmer      195 non-null    float64\n",
      " 10  MDVP:Shimmer(dB)  195 non-null    float64\n",
      " 11  Shimmer:APQ3      195 non-null    float64\n",
      " 12  Shimmer:APQ5      195 non-null    float64\n",
      " 13  MDVP:APQ          195 non-null    float64\n",
      " 14  Shimmer:DDA       195 non-null    float64\n",
      " 15  NHR               195 non-null    float64\n",
      " 16  HNR               195 non-null    float64\n",
      " 17  status            195 non-null    int64  \n",
      " 18  RPDE              195 non-null    float64\n",
      " 19  DFA               195 non-null    float64\n",
      " 20  spread1           195 non-null    float64\n",
      " 21  spread2           195 non-null    float64\n",
      " 22  D2                195 non-null    float64\n",
      " 23  PPE               195 non-null    float64\n",
      "dtypes: float64(22), int64(1), object(1)\n",
      "memory usage: 36.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f16e0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>154.228641</td>\n",
       "      <td>197.104918</td>\n",
       "      <td>116.324631</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.029709</td>\n",
       "      <td>0.282251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046993</td>\n",
       "      <td>0.024847</td>\n",
       "      <td>21.885974</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.498536</td>\n",
       "      <td>0.718099</td>\n",
       "      <td>-5.684397</td>\n",
       "      <td>0.226510</td>\n",
       "      <td>2.381826</td>\n",
       "      <td>0.206552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>41.390065</td>\n",
       "      <td>91.491548</td>\n",
       "      <td>43.521413</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.008903</td>\n",
       "      <td>0.018857</td>\n",
       "      <td>0.194877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030459</td>\n",
       "      <td>0.040418</td>\n",
       "      <td>4.425764</td>\n",
       "      <td>0.431878</td>\n",
       "      <td>0.103942</td>\n",
       "      <td>0.055336</td>\n",
       "      <td>1.090208</td>\n",
       "      <td>0.083406</td>\n",
       "      <td>0.382799</td>\n",
       "      <td>0.090119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>88.333000</td>\n",
       "      <td>102.145000</td>\n",
       "      <td>65.476000</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>8.441000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256570</td>\n",
       "      <td>0.574282</td>\n",
       "      <td>-7.964984</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>1.423287</td>\n",
       "      <td>0.044539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.572000</td>\n",
       "      <td>134.862500</td>\n",
       "      <td>84.291000</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.016505</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024735</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>19.198000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.421306</td>\n",
       "      <td>0.674758</td>\n",
       "      <td>-6.450096</td>\n",
       "      <td>0.174351</td>\n",
       "      <td>2.099125</td>\n",
       "      <td>0.137451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>148.790000</td>\n",
       "      <td>175.829000</td>\n",
       "      <td>104.315000</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.007490</td>\n",
       "      <td>0.022970</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038360</td>\n",
       "      <td>0.011660</td>\n",
       "      <td>22.085000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.495954</td>\n",
       "      <td>0.722254</td>\n",
       "      <td>-5.720868</td>\n",
       "      <td>0.218885</td>\n",
       "      <td>2.361532</td>\n",
       "      <td>0.194052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>182.769000</td>\n",
       "      <td>224.205500</td>\n",
       "      <td>140.018500</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.037885</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060795</td>\n",
       "      <td>0.025640</td>\n",
       "      <td>25.075500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.587562</td>\n",
       "      <td>0.761881</td>\n",
       "      <td>-5.046192</td>\n",
       "      <td>0.279234</td>\n",
       "      <td>2.636456</td>\n",
       "      <td>0.252980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>260.105000</td>\n",
       "      <td>592.030000</td>\n",
       "      <td>239.170000</td>\n",
       "      <td>0.033160</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.021440</td>\n",
       "      <td>0.019580</td>\n",
       "      <td>0.064330</td>\n",
       "      <td>0.119080</td>\n",
       "      <td>1.302000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169420</td>\n",
       "      <td>0.314820</td>\n",
       "      <td>33.047000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685151</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-2.434031</td>\n",
       "      <td>0.450493</td>\n",
       "      <td>3.671155</td>\n",
       "      <td>0.527367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "count   195.000000    195.000000    195.000000      195.000000   \n",
       "mean    154.228641    197.104918    116.324631        0.006220   \n",
       "std      41.390065     91.491548     43.521413        0.004848   \n",
       "min      88.333000    102.145000     65.476000        0.001680   \n",
       "25%     117.572000    134.862500     84.291000        0.003460   \n",
       "50%     148.790000    175.829000    104.315000        0.004940   \n",
       "75%     182.769000    224.205500    140.018500        0.007365   \n",
       "max     260.105000    592.030000    239.170000        0.033160   \n",
       "\n",
       "       MDVP:Jitter(Abs)    MDVP:RAP    MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  \\\n",
       "count        195.000000  195.000000  195.000000  195.000000    195.000000   \n",
       "mean           0.000044    0.003306    0.003446    0.009920      0.029709   \n",
       "std            0.000035    0.002968    0.002759    0.008903      0.018857   \n",
       "min            0.000007    0.000680    0.000920    0.002040      0.009540   \n",
       "25%            0.000020    0.001660    0.001860    0.004985      0.016505   \n",
       "50%            0.000030    0.002500    0.002690    0.007490      0.022970   \n",
       "75%            0.000060    0.003835    0.003955    0.011505      0.037885   \n",
       "max            0.000260    0.021440    0.019580    0.064330      0.119080   \n",
       "\n",
       "       MDVP:Shimmer(dB)  ...  Shimmer:DDA         NHR         HNR      status  \\\n",
       "count        195.000000  ...   195.000000  195.000000  195.000000  195.000000   \n",
       "mean           0.282251  ...     0.046993    0.024847   21.885974    0.753846   \n",
       "std            0.194877  ...     0.030459    0.040418    4.425764    0.431878   \n",
       "min            0.085000  ...     0.013640    0.000650    8.441000    0.000000   \n",
       "25%            0.148500  ...     0.024735    0.005925   19.198000    1.000000   \n",
       "50%            0.221000  ...     0.038360    0.011660   22.085000    1.000000   \n",
       "75%            0.350000  ...     0.060795    0.025640   25.075500    1.000000   \n",
       "max            1.302000  ...     0.169420    0.314820   33.047000    1.000000   \n",
       "\n",
       "             RPDE         DFA     spread1     spread2          D2         PPE  \n",
       "count  195.000000  195.000000  195.000000  195.000000  195.000000  195.000000  \n",
       "mean     0.498536    0.718099   -5.684397    0.226510    2.381826    0.206552  \n",
       "std      0.103942    0.055336    1.090208    0.083406    0.382799    0.090119  \n",
       "min      0.256570    0.574282   -7.964984    0.006274    1.423287    0.044539  \n",
       "25%      0.421306    0.674758   -6.450096    0.174351    2.099125    0.137451  \n",
       "50%      0.495954    0.722254   -5.720868    0.218885    2.361532    0.194052  \n",
       "75%      0.587562    0.761881   -5.046192    0.279234    2.636456    0.252980  \n",
       "max      0.685151    0.825288   -2.434031    0.450493    3.671155    0.527367  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecc1209a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48cc3310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>0.426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>0.626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>0.482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>0.517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>0.584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>174.188</td>\n",
       "      <td>230.978</td>\n",
       "      <td>94.261</td>\n",
       "      <td>0.00459</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00263</td>\n",
       "      <td>0.00259</td>\n",
       "      <td>0.00790</td>\n",
       "      <td>0.04087</td>\n",
       "      <td>0.405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07008</td>\n",
       "      <td>0.02764</td>\n",
       "      <td>19.517</td>\n",
       "      <td>0</td>\n",
       "      <td>0.448439</td>\n",
       "      <td>0.657899</td>\n",
       "      <td>-6.538586</td>\n",
       "      <td>0.121952</td>\n",
       "      <td>2.657476</td>\n",
       "      <td>0.133050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>209.516</td>\n",
       "      <td>253.017</td>\n",
       "      <td>89.488</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00331</td>\n",
       "      <td>0.00292</td>\n",
       "      <td>0.00994</td>\n",
       "      <td>0.02751</td>\n",
       "      <td>0.263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04812</td>\n",
       "      <td>0.01810</td>\n",
       "      <td>19.147</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431674</td>\n",
       "      <td>0.683244</td>\n",
       "      <td>-6.195325</td>\n",
       "      <td>0.129303</td>\n",
       "      <td>2.784312</td>\n",
       "      <td>0.168895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>174.688</td>\n",
       "      <td>240.005</td>\n",
       "      <td>74.287</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00624</td>\n",
       "      <td>0.00564</td>\n",
       "      <td>0.01873</td>\n",
       "      <td>0.02308</td>\n",
       "      <td>0.256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03804</td>\n",
       "      <td>0.10715</td>\n",
       "      <td>17.883</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407567</td>\n",
       "      <td>0.655683</td>\n",
       "      <td>-6.787197</td>\n",
       "      <td>0.158453</td>\n",
       "      <td>2.679772</td>\n",
       "      <td>0.131728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>198.764</td>\n",
       "      <td>396.961</td>\n",
       "      <td>74.904</td>\n",
       "      <td>0.00740</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00390</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.02296</td>\n",
       "      <td>0.241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03794</td>\n",
       "      <td>0.07223</td>\n",
       "      <td>19.020</td>\n",
       "      <td>0</td>\n",
       "      <td>0.451221</td>\n",
       "      <td>0.643956</td>\n",
       "      <td>-6.744577</td>\n",
       "      <td>0.207454</td>\n",
       "      <td>2.138608</td>\n",
       "      <td>0.123306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>214.289</td>\n",
       "      <td>260.277</td>\n",
       "      <td>77.973</td>\n",
       "      <td>0.00567</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.00317</td>\n",
       "      <td>0.00885</td>\n",
       "      <td>0.01884</td>\n",
       "      <td>0.190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03078</td>\n",
       "      <td>0.04398</td>\n",
       "      <td>21.209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.462803</td>\n",
       "      <td>0.664357</td>\n",
       "      <td>-5.724056</td>\n",
       "      <td>0.190667</td>\n",
       "      <td>2.555477</td>\n",
       "      <td>0.148569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0        119.992       157.302        74.997         0.00784   \n",
       "1        122.400       148.650       113.819         0.00968   \n",
       "2        116.682       131.111       111.555         0.01050   \n",
       "3        116.676       137.871       111.366         0.00997   \n",
       "4        116.014       141.781       110.655         0.01284   \n",
       "..           ...           ...           ...             ...   \n",
       "190      174.188       230.978        94.261         0.00459   \n",
       "191      209.516       253.017        89.488         0.00564   \n",
       "192      174.688       240.005        74.287         0.01360   \n",
       "193      198.764       396.961        74.904         0.00740   \n",
       "194      214.289       260.277        77.973         0.00567   \n",
       "\n",
       "     MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  \\\n",
       "0             0.00007   0.00370   0.00554     0.01109       0.04374   \n",
       "1             0.00008   0.00465   0.00696     0.01394       0.06134   \n",
       "2             0.00009   0.00544   0.00781     0.01633       0.05233   \n",
       "3             0.00009   0.00502   0.00698     0.01505       0.05492   \n",
       "4             0.00011   0.00655   0.00908     0.01966       0.06425   \n",
       "..                ...       ...       ...         ...           ...   \n",
       "190           0.00003   0.00263   0.00259     0.00790       0.04087   \n",
       "191           0.00003   0.00331   0.00292     0.00994       0.02751   \n",
       "192           0.00008   0.00624   0.00564     0.01873       0.02308   \n",
       "193           0.00004   0.00370   0.00390     0.01109       0.02296   \n",
       "194           0.00003   0.00295   0.00317     0.00885       0.01884   \n",
       "\n",
       "     MDVP:Shimmer(dB)  ...  Shimmer:DDA      NHR     HNR  status      RPDE  \\\n",
       "0               0.426  ...      0.06545  0.02211  21.033       1  0.414783   \n",
       "1               0.626  ...      0.09403  0.01929  19.085       1  0.458359   \n",
       "2               0.482  ...      0.08270  0.01309  20.651       1  0.429895   \n",
       "3               0.517  ...      0.08771  0.01353  20.644       1  0.434969   \n",
       "4               0.584  ...      0.10470  0.01767  19.649       1  0.417356   \n",
       "..                ...  ...          ...      ...     ...     ...       ...   \n",
       "190             0.405  ...      0.07008  0.02764  19.517       0  0.448439   \n",
       "191             0.263  ...      0.04812  0.01810  19.147       0  0.431674   \n",
       "192             0.256  ...      0.03804  0.10715  17.883       0  0.407567   \n",
       "193             0.241  ...      0.03794  0.07223  19.020       0  0.451221   \n",
       "194             0.190  ...      0.03078  0.04398  21.209       0  0.462803   \n",
       "\n",
       "          DFA   spread1   spread2        D2       PPE  \n",
       "0    0.815285 -4.813031  0.266482  2.301442  0.284654  \n",
       "1    0.819521 -4.075192  0.335590  2.486855  0.368674  \n",
       "2    0.825288 -4.443179  0.311173  2.342259  0.332634  \n",
       "3    0.819235 -4.117501  0.334147  2.405554  0.368975  \n",
       "4    0.823484 -3.747787  0.234513  2.332180  0.410335  \n",
       "..        ...       ...       ...       ...       ...  \n",
       "190  0.657899 -6.538586  0.121952  2.657476  0.133050  \n",
       "191  0.683244 -6.195325  0.129303  2.784312  0.168895  \n",
       "192  0.655683 -6.787197  0.158453  2.679772  0.131728  \n",
       "193  0.643956 -6.744577  0.207454  2.138608  0.123306  \n",
       "194  0.664357 -5.724056  0.190667  2.555477  0.148569  \n",
       "\n",
       "[195 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unnesscery columns\n",
    "data = data.drop(['name'], axis = 1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75104082",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad6580fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['MDVP:Jitter(%)'].value_counts().plot(kind='hist',)\n",
    "\n",
    "#  irregularities in vocal pitch, commonly seen in Parkinson’s patients on range of 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0203f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['MDVP:RAP'].value_counts().plot(kind='hist')\n",
    "\n",
    "#  amplitude-related issues in speech are more in range 1.o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d21bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='status', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='status', data=data)\n",
    "\n",
    "# data indicates around 150 people are having parkinson disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1460318a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAhFElEQVR4nO3db0zd5f3/8deRf2drBRGaQ3HYHjSZ1NYoB4OQnLkb3anUO01oxJrQxmwmJ7tRgdT0Dxq7mnlq2yxd1wJppYlssZINNU1ECy6WkHFaV0KZXz1bupQJbc8RD/vmHF2/AsXP70Z/PdvZOaUcqlIuno/kJOPi/TnXdZYsPPfhcGqzLMsSAADAPHfbXB8AAADgm0DUAAAAIxA1AADACEQNAAAwAlEDAACMQNQAAAAjEDUAAMAIRA0AADBC+lwf4Lv09ddf69KlS7r99ttls9nm+jgAAGAGLMvSF198ocLCQt122/XvxyyoqLl06ZKKiorm+hgAAGAWRkZG9IMf/OC6319QUXP77bdLuvpfSnZ29hyfBgAAzEQ0GlVRUVHs5/j1LKioufYrp+zsbKIGAIB55kZvHeGNwgAAwAhEDQAAMAJRAwAAjEDUAAAAIxA1AADACEQNAAAwAlEDAACMQNQAAAAjEDUAAMAIRA0AADACUQMAAIxA1AAAACMsqH/QEoCZnn32WX3++eeSpCVLlujXv/71HJ8IwFwgagDMe59//rk+++yzuT4GgDnGr58AAIARiBoAAGAEogYAABiBqAEAAEYgagAAgBGIGgAAYASiBgAAGIGoAQAARiBqAACAEYgaAABgBKIGAAAYgagBAABGIGoAAIARZhU1TU1Ncjqdstvtcrlc6u3tnXa+p6dHLpdLdrtdxcXFamlpifv+m2++qbKyMt1xxx1atGiRHnzwQf32t7+96X0BAMDCkXLUtLe3q66uTo2NjRoYGJDb7VZVVZWGh4eTzg8NDWnt2rVyu90aGBjQjh07tHnzZnV0dMRm7rzzTjU2Nsrv9+svf/mLnn76aT399NM6ceLErPcFAAALi82yLCuVC8rLy1VaWqrm5ubYWklJidatWyefz5cwv3XrVh0/flyBQCC25vV6NTg4KL/ff919SktL9fjjj+ull16a1b7JRKNR5eTkKBKJKDs7e0bXALj1PfXUU/rss88kSQ6HQ6+//vocnwjAN2mmP79TulMzMTGh/v5+eTyeuHWPx6O+vr6k1/j9/oT5NWvW6MyZM5qcnEyYtyxLf/zjH/W3v/1NP/rRj2a9rySNj48rGo3GPQAAgJlSippwOKypqSk5HI64dYfDoVAolPSaUCiUdP7KlSsKh8OxtUgkosWLFyszM1OPP/64fvOb3+gnP/nJrPeVJJ/Pp5ycnNijqKgolZcLAADmkVm9Udhms8V9bVlWwtqN5v97/fbbb9fZs2f15z//Wb/85S/V0NCgkydP3tS+27dvVyQSiT1GRkamfV0AAGD+Sk9lOD8/X2lpaQl3R0ZHRxPuolxTUFCQdD49PV15eXmxtdtuu0333nuvJOnBBx9UIBCQz+fTj3/841ntK0lZWVnKyspK5SUCAIB5KqU7NZmZmXK5XOru7o5b7+7uVmVlZdJrKioqEua7urpUVlamjIyM6+5lWZbGx8dnvS8AAFhYUrpTI0kNDQ2qra1VWVmZKioqdPjwYQ0PD8vr9Uq6+iufixcvqq2tTdLVv3Q6ePCgGhoa9Mwzz8jv96u1tVXHjh2LPafP51NZWZnuueceTUxMqLOzU21tbXF/6XSjfQEAwMKWctTU1NRobGxMu3btUjAY1MqVK9XZ2ally5ZJkoLBYNxnxzidTnV2dqq+vl6HDh1SYWGhDhw4oOrq6tjMv/71L/385z/XhQsX9L3vfU/33Xeffve736mmpmbG+wIAgIUt5c+pmc/4nBrATHxODWC2b+VzagAAAG5VRA0AADACUQMAAIxA1AAAACMQNQAAwAhEDQAAMAJRAwAAjEDUAAAAIxA1AADACEQNAAAwAlEDAACMQNQAAAAjEDUAAMAIRA0AADACUQMAAIxA1AAAACMQNQAAwAhEDQAAMAJRAwAAjEDUAAAAIxA1AADACEQNAAAwAlEDAACMQNQAAAAjEDUAAMAIRA0AADACUQMAAIxA1AAAACMQNQAAwAhEDQAAMAJRAwAAjEDUAAAAIxA1AADACEQNAAAwAlEDAACMQNQAAAAjEDUAAMAIRA0AADACUQMAAIxA1AAAACMQNQAAwAhEDQAAMAJRAwAAjEDUAAAAIxA1AADACLOKmqamJjmdTtntdrlcLvX29k4739PTI5fLJbvdruLiYrW0tMR9/8iRI3K73crNzVVubq5Wr16tDz/8MG5m586dstlscY+CgoLZHB8AABgo5ahpb29XXV2dGhsbNTAwILfbraqqKg0PDyedHxoa0tq1a+V2uzUwMKAdO3Zo8+bN6ujoiM2cPHlSGzZs0AcffCC/36+7775bHo9HFy9ejHuu+++/X8FgMPb46KOPUj0+AAAwlM2yLCuVC8rLy1VaWqrm5ubYWklJidatWyefz5cwv3XrVh0/flyBQCC25vV6NTg4KL/fn3SPqakp5ebm6uDBg9q4caOkq3dq3n77bZ09ezaV48aJRqPKyclRJBJRdnb2rJ8HwK3lqaee0meffSZJcjgcev311+f4RAC+STP9+Z3SnZqJiQn19/fL4/HErXs8HvX19SW9xu/3J8yvWbNGZ86c0eTkZNJrLl++rMnJSd15551x6+fOnVNhYaGcTqeefPJJnT9/ftrzjo+PKxqNxj0AAICZUoqacDisqakpORyOuHWHw6FQKJT0mlAolHT+ypUrCofDSa/Ztm2b7rrrLq1evTq2Vl5erra2Np04cUJHjhxRKBRSZWWlxsbGrnten8+nnJyc2KOoqGimLxUAAMwzs3qjsM1mi/vasqyEtRvNJ1uXpD179ujYsWN68803ZbfbY+tVVVWqrq7WqlWrtHr1ar3zzjuSpNdee+26+27fvl2RSCT2GBkZufGLAwAA81J6KsP5+flKS0tLuCszOjqacDfmmoKCgqTz6enpysvLi1vft2+fXn75Zb3//vt64IEHpj3LokWLtGrVKp07d+66M1lZWcrKypr2eeYj13Ntc30E4JaS/b9fxv4fWvB/v+R/I8B/6N+7ca6P8J1J6U5NZmamXC6Xuru749a7u7tVWVmZ9JqKioqE+a6uLpWVlSkjIyO2tnfvXr300kt67733VFZWdsOzjI+PKxAIaOnSpam8BAAAYKiUf/3U0NCgV199VUePHlUgEFB9fb2Gh4fl9XolXf2Vz7W/WJKu/qXTp59+qoaGBgUCAR09elStra3asmVLbGbPnj16/vnndfToUS1fvlyhUEihUEhffvllbGbLli3q6enR0NCQTp8+rfXr1ysajWrTpk038/oBAIAhUvr1kyTV1NRobGxMu3btUjAY1MqVK9XZ2ally5ZJkoLBYNxn1jidTnV2dqq+vl6HDh1SYWGhDhw4oOrq6thMU1OTJiYmtH79+ri9XnzxRe3cuVOSdOHCBW3YsEHhcFhLlizRI488olOnTsX2BQAAC1vKn1Mzn5nyOTW8XwCIl/0/f9BtE/+SJH2duUjRletvcAWwcJjwnppv5XNqAAAAblVEDQAAMAJRAwAAjEDUAAAAIxA1AADACEQNAAAwAlEDAACMQNQAAAAjEDUAAMAIRA0AADACUQMAAIxA1AAAACMQNQAAwAhEDQAAMAJRAwAAjEDUAAAAIxA1AADACEQNAAAwAlEDAACMQNQAAAAjEDUAAMAIRA0AADACUQMAAIxA1AAAACMQNQAAwAhEDQAAMAJRAwAAjEDUAAAAIxA1AADACEQNAAAwAlEDAACMQNQAAAAjEDUAAMAIRA0AADACUQMAAIxA1AAAACMQNQAAwAhEDQAAMAJRAwAAjEDUAAAAIxA1AADACEQNAAAwAlEDAACMQNQAAAAjEDUAAMAIs4qapqYmOZ1O2e12uVwu9fb2Tjvf09Mjl8slu92u4uJitbS0xH3/yJEjcrvdys3NVW5urlavXq0PP/zwpvcFAAALR8pR097errq6OjU2NmpgYEBut1tVVVUaHh5OOj80NKS1a9fK7XZrYGBAO3bs0ObNm9XR0RGbOXnypDZs2KAPPvhAfr9fd999tzwejy5evDjrfQEAwMJisyzLSuWC8vJylZaWqrm5ObZWUlKidevWyefzJcxv3bpVx48fVyAQiK15vV4NDg7K7/cn3WNqakq5ubk6ePCgNm7cOKt9k4lGo8rJyVEkElF2dvaMrrkVuZ5rm+sjALeU7P/5g26b+Jck6evMRYquXD/HJwJuHf17N871EW7aTH9+p3SnZmJiQv39/fJ4PHHrHo9HfX19Sa/x+/0J82vWrNGZM2c0OTmZ9JrLly9rcnJSd95556z3laTx8XFFo9G4BwAAMFNKURMOhzU1NSWHwxG37nA4FAqFkl4TCoWSzl+5ckXhcDjpNdu2bdNdd92l1atXz3pfSfL5fMrJyYk9ioqKbvgaAQDA/DSrNwrbbLa4ry3LSli70XyydUnas2ePjh07pjfffFN2u/2m9t2+fbsikUjsMTIyct1ZAPPX1xmL9HXm/39kLJrr4wCYI+mpDOfn5ystLS3h7sjo6GjCXZRrCgoKks6np6crLy8vbn3fvn16+eWX9f777+uBBx64qX0lKSsrS1lZWTN6bQDmry9/WDXXRwBwC0jpTk1mZqZcLpe6u7vj1ru7u1VZWZn0moqKioT5rq4ulZWVKSMjI7a2d+9evfTSS3rvvfdUVlZ20/sCAICFJaU7NZLU0NCg2tpalZWVqaKiQocPH9bw8LC8Xq+kq7/yuXjxotrarv6Fjtfr1cGDB9XQ0KBnnnlGfr9fra2tOnbsWOw59+zZoxdeeEGvv/66li9fHrsjs3jxYi1evHhG+wIAgIUt5aipqanR2NiYdu3apWAwqJUrV6qzs1PLli2TJAWDwbjPjnE6ners7FR9fb0OHTqkwsJCHThwQNXV1bGZpqYmTUxMaP36+D/DfPHFF7Vz584Z7QsAABa2lD+nZj7jc2oAAAsNn1MDAAAwzxA1AADACEQNAAAwAlEDAACMQNQAAAAjEDUAAMAIRA0AADACUQMAAIxA1AAAACMQNQAAwAhEDQAAMAJRAwAAjEDUAAAAIxA1AADACEQNAAAwAlEDAACMQNQAAAAjEDUAAMAIRA0AADACUQMAAIxA1AAAACMQNQAAwAhEDQAAMAJRAwAAjEDUAAAAIxA1AADACEQNAAAwAlEDAACMQNQAAAAjEDUAAMAIRA0AADACUQMAAIxA1AAAACMQNQAAwAhEDQAAMAJRAwAAjEDUAAAAIxA1AADACEQNAAAwAlEDAACMQNQAAAAjEDUAAMAIRA0AADACUQMAAIxA1AAAACPMKmqamprkdDplt9vlcrnU29s77XxPT49cLpfsdruKi4vV0tIS9/2PP/5Y1dXVWr58uWw2m/bv35/wHDt37pTNZot7FBQUzOb4AADAQClHTXt7u+rq6tTY2KiBgQG53W5VVVVpeHg46fzQ0JDWrl0rt9utgYEB7dixQ5s3b1ZHR0ds5vLlyyouLtbu3bunDZX7779fwWAw9vjoo49SPT4AADBUeqoX/OpXv9JPf/pT/exnP5Mk7d+/XydOnFBzc7N8Pl/CfEtLi+6+++7Y3ZeSkhKdOXNG+/btU3V1tSTp4Ycf1sMPPyxJ2rZt2/UPm57O3RkAAJBUSndqJiYm1N/fL4/HE7fu8XjU19eX9Bq/358wv2bNGp05c0aTk5MpHfbcuXMqLCyU0+nUk08+qfPnz087Pz4+rmg0GvcAAABmSilqwuGwpqam5HA44tYdDodCoVDSa0KhUNL5K1euKBwOz3jv8vJytbW16cSJEzpy5IhCoZAqKys1NjZ23Wt8Pp9ycnJij6KiohnvBwAA5pdZvVHYZrPFfW1ZVsLajeaTrU+nqqpK1dXVWrVqlVavXq133nlHkvTaa69d95rt27crEonEHiMjIzPeDwAAzC8pvacmPz9faWlpCXdlRkdHE+7GXFNQUJB0Pj09XXl5eSke998WLVqkVatW6dy5c9edycrKUlZW1qz3AAAA80dKd2oyMzPlcrnU3d0dt97d3a3Kysqk11RUVCTMd3V1qaysTBkZGSke99/Gx8cVCAS0dOnSWT8HAAAwR8q/fmpoaNCrr76qo0ePKhAIqL6+XsPDw/J6vZKu/spn48aNsXmv16tPP/1UDQ0NCgQCOnr0qFpbW7Vly5bYzMTEhM6ePauzZ89qYmJCFy9e1NmzZ/X3v/89NrNlyxb19PRoaGhIp0+f1vr16xWNRrVp06abef0AAMAQKf9Jd01NjcbGxrRr1y4Fg0GtXLlSnZ2dWrZsmSQpGAzGfWaN0+lUZ2en6uvrdejQIRUWFurAgQOxP+eWpEuXLumhhx6Kfb1v3z7t27dPjz76qE6ePClJunDhgjZs2KBwOKwlS5bokUce0alTp2L7AgCAhc1mXXvX7gIQjUaVk5OjSCSi7OzsuT7OrLmea5vrIwAA5on+vRtvPHSLm+nPb/7tJwAAYASiBgAAGIGoAQAARiBqAACAEYgaAABgBKIGAAAYgagBAABGIGoAAIARiBoAAGAEogYAABiBqAEAAEYgagAAgBGIGgAAYASiBgAAGIGoAQAARiBqAACAEYgaAABgBKIGAAAYgagBAABGIGoAAIARiBoAAGAEogYAABiBqAEAAEYgagAAgBGIGgAAYASiBgAAGIGoAQAARiBqAACAEYgaAABgBKIGAAAYgagBAABGIGoAAIARiBoAAGAEogYAABiBqAEAAEYgagAAgBGIGgAAYASiBgAAGIGoAQAARiBqAACAEYgaAABgBKIGAAAYgagBAABGIGoAAIARZhU1TU1Ncjqdstvtcrlc6u3tnXa+p6dHLpdLdrtdxcXFamlpifv+xx9/rOrqai1fvlw2m0379+//RvYFAAALR8pR097errq6OjU2NmpgYEBut1tVVVUaHh5OOj80NKS1a9fK7XZrYGBAO3bs0ObNm9XR0RGbuXz5soqLi7V7924VFBR8I/sCAICFxWZZlpXKBeXl5SotLVVzc3NsraSkROvWrZPP50uY37p1q44fP65AIBBb83q9GhwclN/vT5hfvny56urqVFdXd1P7JhONRpWTk6NIJKLs7OwZXXMrcj3XNtdHAADME/17N871EW7aTH9+p3SnZmJiQv39/fJ4PHHrHo9HfX19Sa/x+/0J82vWrNGZM2c0OTn5re0LAAAWlvRUhsPhsKampuRwOOLWHQ6HQqFQ0mtCoVDS+StXrigcDmvp0qXfyr6SND4+rvHx8djX0Wj0hnsBAID5aVZvFLbZbHFfW5aVsHaj+WTr3/S+Pp9POTk5sUdRUVFK+wEAgPkjpajJz89XWlpawt2R0dHRhLso1xQUFCSdT09PV15e3re2ryRt375dkUgk9hgZGZnRfgAAYP5JKWoyMzPlcrnU3d0dt97d3a3Kysqk11RUVCTMd3V1qaysTBkZGd/avpKUlZWl7OzsuAcAADBTSu+pkaSGhgbV1taqrKxMFRUVOnz4sIaHh+X1eiVdvTty8eJFtbVd/Qsdr9ergwcPqqGhQc8884z8fr9aW1t17Nix2HNOTEzok08+if3nixcv6uzZs1q8eLHuvffeGe0LAAAWtpSjpqamRmNjY9q1a5eCwaBWrlypzs5OLVu2TJIUDAbjPjvG6XSqs7NT9fX1OnTokAoLC3XgwAFVV1fHZi5duqSHHnoo9vW+ffu0b98+Pfroozp58uSM9gUAAAtbyp9TM5/xOTUAgIWGz6kBAACYZ4gaAABgBKIGAAAYgagBAABGIGoAAIARiBoAAGAEogYAABiBqAEAAEYgagAAgBGIGgAAYASiBgAAGIGoAQAARiBqAACAEYgaAABgBKIGAAAYgagBAABGIGoAAIARiBoAAGAEogYAABiBqAEAAEYgagAAgBGIGgAAYASiBgAAGIGoAQAARiBqAACAEYgaAABgBKIGAAAYgagBAABGIGoAAIARiBoAAGAEogYAABiBqAEAAEYgagAAgBGIGgAAYASiBgAAGIGoAQAARiBqAACAEYgaAABgBKIGAAAYgagBAABGIGoAAIARiBoAAGAEogYAABiBqAEAAEYgagAAgBFmFTVNTU1yOp2y2+1yuVzq7e2ddr6np0cul0t2u13FxcVqaWlJmOno6NCKFSuUlZWlFStW6K233or7/s6dO2Wz2eIeBQUFszk+AAAwUMpR097errq6OjU2NmpgYEBut1tVVVUaHh5OOj80NKS1a9fK7XZrYGBAO3bs0ObNm9XR0RGb8fv9qqmpUW1trQYHB1VbW6snnnhCp0+fjnuu+++/X8FgMPb46KOPUj0+AAAwlM2yLCuVC8rLy1VaWqrm5ubYWklJidatWyefz5cwv3XrVh0/flyBQCC25vV6NTg4KL/fL0mqqalRNBrVu+++G5t57LHHlJubq2PHjkm6eqfm7bff1tmzZ1N6gf8pGo0qJydHkUhE2dnZs36eueZ6rm2ujwAAmCf6926c6yPctJn+/E7pTs3ExIT6+/vl8Xji1j0ej/r6+pJe4/f7E+bXrFmjM2fOaHJyctqZ/37Oc+fOqbCwUE6nU08++aTOnz8/7XnHx8cVjUbjHgAAwEwpRU04HNbU1JQcDkfcusPhUCgUSnpNKBRKOn/lyhWFw+FpZ/7zOcvLy9XW1qYTJ07oyJEjCoVCqqys1NjY2HXP6/P5lJOTE3sUFRWl8nIBAMA8Mqs3CttstrivLctKWLvR/H+v3+g5q6qqVF1drVWrVmn16tV65513JEmvvfbadffdvn27IpFI7DEyMnKDVwYAAOar9FSG8/PzlZaWlnBXZnR0NOFOyzUFBQVJ59PT05WXlzftzPWeU5IWLVqkVatW6dy5c9edycrKUlZW1rSvCQAAmCGlOzWZmZlyuVzq7u6OW+/u7lZlZWXSayoqKhLmu7q6VFZWpoyMjGlnrvec0tX3ywQCAS1dujSVlwAAAAyV8q+fGhoa9Oqrr+ro0aMKBAKqr6/X8PCwvF6vpKu/8tm48d/vtPZ6vfr000/V0NCgQCCgo0ePqrW1VVu2bInNPPvss+rq6tIrr7yiv/71r3rllVf0/vvvq66uLjazZcsW9fT0aGhoSKdPn9b69esVjUa1adOmm3j5AADAFCn9+km6+ufXY2Nj2rVrl4LBoFauXKnOzk4tW7ZMkhQMBuM+s8bpdKqzs1P19fU6dOiQCgsLdeDAAVVXV8dmKisr9cYbb+j555/XCy+8oHvuuUft7e0qLy+PzVy4cEEbNmxQOBzWkiVL9Mgjj+jUqVOxfQEAwMKW8ufUzGd8Tg0AYKHhc2oAAADmGaIGAAAYgagBAABGIGoAAIARiBoAAGAEogYAABiBqAEAAEYgagAAgBGIGgAAYASiBgAAGIGoAQAARiBqAACAEYgaAABgBKIGAAAYgagBAABGIGoAAIARiBoAAGAEogYAABiBqAEAAEYgagAAgBGIGgAAYASiBgAAGIGoAQAARiBqAACAEYgaAABgBKIGAAAYgagBAABGIGoAAIARiBoAAGAEogYAABiBqAEAAEYgagAAgBGIGgAAYASiBgAAGIGoAQAARiBqAACAEYgaAABgBKIGAAAYgagBAABGIGoAAIARiBoAAGAEogYAABiBqAEAAEYgagAAgBGIGgAAYIRZRU1TU5OcTqfsdrtcLpd6e3unne/p6ZHL5ZLdbldxcbFaWloSZjo6OrRixQplZWVpxYoVeuutt256XwAAsHCkHDXt7e2qq6tTY2OjBgYG5Ha7VVVVpeHh4aTzQ0NDWrt2rdxutwYGBrRjxw5t3rxZHR0dsRm/36+amhrV1tZqcHBQtbW1euKJJ3T69OlZ7wsAABYWm2VZVioXlJeXq7S0VM3NzbG1kpISrVu3Tj6fL2F+69atOn78uAKBQGzN6/VqcHBQfr9fklRTU6NoNKp33303NvPYY48pNzdXx44dm9W+yUSjUeXk5CgSiSg7OzuVl31LcT3XNtdHAADME/17N871EW7aTH9+p6fypBMTE+rv79e2bdvi1j0ej/r6+pJe4/f75fF44tbWrFmj1tZWTU5OKiMjQ36/X/X19Qkz+/fvn/W+kjQ+Pq7x8fHY15FIRNLV/3Lms6nx/5vrIwAA5on5/jNP+vdruNF9mJSiJhwOa2pqSg6HI27d4XAoFAolvSYUCiWdv3LlisLhsJYuXXrdmWvPOZt9Jcnn8+kXv/hFwnpRUdH1XyQAAAbJ+Y13ro/wjfniiy+Uk5Nz3e+nFDXX2Gy2uK8ty0pYu9H8f6/P5DlT3Xf79u1qaGiIff3111/rn//8p/Ly8qa9DsD8E41GVVRUpJGRkXn962UAiSzL0hdffKHCwsJp51KKmvz8fKWlpSXcHRkdHU24i3JNQUFB0vn09HTl5eVNO3PtOWezryRlZWUpKysrbu2OO+64/gsEMO9lZ2cTNYCBprtDc01Kf/2UmZkpl8ul7u7uuPXu7m5VVlYmvaaioiJhvqurS2VlZcrIyJh25tpzzmZfAACwwFgpeuONN6yMjAyrtbXV+uSTT6y6ujpr0aJF1j/+8Q/Lsixr27ZtVm1tbWz+/Pnz1ve//32rvr7e+uSTT6zW1lYrIyPD+sMf/hCb+dOf/mSlpaVZu3fvtgKBgLV7924rPT3dOnXq1Iz3BbCwRSIRS5IViUTm+igA5kjKUWNZlnXo0CFr2bJlVmZmplVaWmr19PTEvrdp0ybr0UcfjZs/efKk9dBDD1mZmZnW8uXLrebm5oTn/P3vf2/98Ic/tDIyMqz77rvP6ujoSGlfAAvbV199Zb344ovWV199NddHATBHUv6cGgAAgFsR//YTAAAwAlEDAACMQNQAAAAjEDUAAMAIRA2Aea+pqUlOp1N2u10ul0u9vb1zfSQAc4CoATCvtbe3q66uTo2NjRoYGJDb7VZVVZWGh4fn+mgAvmP8STeAea28vFylpaVqbm6OrZWUlGjdunXy+XxzeDIA3zXu1ACYtyYmJtTf3y+PxxO37vF41NfXN0enAjBXiBoA81Y4HNbU1FTCP2zrcDgS/gFcAOYjagDMezabLe5ry7IS1gCYj6gBMG/l5+crLS0t4a7M6Ohowt0bAOYjagDMW5mZmXK5XOru7o5b7+7uVmVl5RydCsBcSZ/rAwDAzWhoaFBtba3KyspUUVGhw4cPa3h4WF6vd66PBuA7RtQAmNdqamo0NjamXbt2KRgMauXKlers7NSyZcvm+mgAvmN8Tg0AADAC76kBAABGIGoAAIARiBoAAGAEogYAABiBqAEAAEYgagAAgBGIGgAAYASiBgAAGIGoAQAARiBqAACAEYgaAABgBKIGAAAY4f8Bbaa8qLyJkDwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data['NHR'])\n",
    "\n",
    "# most patients are having NHR value between 0 to 0.025.highest is 0.030\n",
    "# Higher NHR values indicate a hoarse or breathy voice, common in Parkinson's patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22251d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='HNR', ylabel='Count'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data['HNR'])\n",
    "\n",
    "# Higher HNR values indicate clearer voice quality,\n",
    "# while lower values indicate a breathy or strained voice, which can be a symptom of Parkinson’s disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d63d604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data['PPE'])\n",
    "\n",
    "# most people having irregularities in voice pitch are more in range 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e71d1d",
   "metadata": {},
   "source": [
    "# model building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7aced6",
   "metadata": {},
   "source": [
    "# we use total 8 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b2b902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary columns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score,KFold,StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "389e9df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix target and features\n",
    "X = data.drop(columns=['status'])  # Features\n",
    "y = data['status']  # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "296e8e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data to training and testing sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c96646fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models and val\n",
    "val = [KFold(n_splits=5, shuffle=True, random_state=42),StratifiedKFold(n_splits=5, shuffle=True, random_state=42)]\n",
    "models = [LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=42),\n",
    "          DecisionTreeClassifier(random_state=42),\n",
    "          GaussianNB(),\n",
    "          RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "          KNeighborsClassifier(n_neighbors=5),\n",
    "          SVC(kernel='linear', random_state=42),\n",
    "          GradientBoostingClassifier(),\n",
    "          XGBClassifier(eval_metric='mlogloss') \n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72df2387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(multi_class='multinomial', random_state=42)\n",
      "KFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.8512820512820513\n",
      "----------------------------------------\n",
      "DecisionTreeClassifier(random_state=42)\n",
      "KFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.8564102564102564\n",
      "----------------------------------------\n",
      "GaussianNB()\n",
      "KFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.6974358974358974\n",
      "----------------------------------------\n",
      "RandomForestClassifier(random_state=42)\n",
      "KFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.9179487179487179\n",
      "----------------------------------------\n",
      "KNeighborsClassifier()\n",
      "KFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.8461538461538461\n",
      "----------------------------------------\n",
      "SVC(kernel='linear', random_state=42)\n",
      "KFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.8564102564102564\n",
      "----------------------------------------\n",
      "GradientBoostingClassifier()\n",
      "KFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.9128205128205128\n",
      "----------------------------------------\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)\n",
      "KFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.9179487179487179\n",
      "----------------------------------------\n",
      "LogisticRegression(multi_class='multinomial', random_state=42)\n",
      "StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.8564102564102564\n",
      "----------------------------------------\n",
      "DecisionTreeClassifier(random_state=42)\n",
      "StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.8615384615384615\n",
      "----------------------------------------\n",
      "GaussianNB()\n",
      "StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.7076923076923076\n",
      "----------------------------------------\n",
      "RandomForestClassifier(random_state=42)\n",
      "StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.8871794871794872\n",
      "----------------------------------------\n",
      "KNeighborsClassifier()\n",
      "StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.8205128205128205\n",
      "----------------------------------------\n",
      "SVC(kernel='linear', random_state=42)\n",
      "StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.8564102564102564\n",
      "----------------------------------------\n",
      "GradientBoostingClassifier()\n",
      "StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.9179487179487179\n",
      "----------------------------------------\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=None, ...)\n",
      "StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
      "0.9384615384615385\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in val:\n",
    "    for j in models:\n",
    "        score  = cross_val_score(estimator=j,cv=i,X=X,y=y)\n",
    "        print(j)\n",
    "        print(i)\n",
    "        print(score.mean())\n",
    "        print('----'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda30a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have best scores in random forest classifier, xgboost, and gradiant boosting classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1cd30",
   "metadata": {},
   "source": [
    "# Resampling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02024e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary columns\n",
    "from imblearn.over_sampling import RandomOverSampler,SMOTE, ADASYN\n",
    "from imblearn.under_sampling import TomekLinks, RandomUnderSampler, EditedNearestNeighbours\n",
    "from imblearn.combine import SMOTEENN,SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f6debbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models and resamplers\n",
    "models = [LogisticRegression(),DecisionTreeClassifier(),GaussianNB(),RandomForestClassifier(),KNeighborsClassifier(),SVC(),GradientBoostingClassifier(),XGBClassifier()]\n",
    "resamplers = [RandomOverSampler(),SMOTE(),ADASYN(),TomekLinks(),RandomUnderSampler(),EditedNearestNeighbours(),SMOTEENN(),SMOTETomek()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "87e8e58b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "RandomOverSampler()\n",
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.75      0.79        28\n",
      "           1       0.79      0.87      0.83        31\n",
      "\n",
      "    accuracy                           0.81        59\n",
      "   macro avg       0.82      0.81      0.81        59\n",
      "weighted avg       0.82      0.81      0.81        59\n",
      "\n",
      "0.8135593220338984\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "RandomOverSampler()\n",
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        31\n",
      "           1       1.00      0.93      0.96        28\n",
      "\n",
      "    accuracy                           0.97        59\n",
      "   macro avg       0.97      0.96      0.97        59\n",
      "weighted avg       0.97      0.97      0.97        59\n",
      "\n",
      "0.9661016949152542\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "RandomOverSampler()\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82        28\n",
      "           1       1.00      0.61      0.76        31\n",
      "\n",
      "    accuracy                           0.80        59\n",
      "   macro avg       0.85      0.81      0.79        59\n",
      "weighted avg       0.86      0.80      0.79        59\n",
      "\n",
      "0.7966101694915254\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "RandomOverSampler()\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        35\n",
      "           1       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.95        59\n",
      "   macro avg       0.96      0.94      0.95        59\n",
      "weighted avg       0.95      0.95      0.95        59\n",
      "\n",
      "0.9491525423728814\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "RandomOverSampler()\n",
      "KNeighborsClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.87        30\n",
      "           1       0.95      0.72      0.82        29\n",
      "\n",
      "    accuracy                           0.85        59\n",
      "   macro avg       0.87      0.85      0.84        59\n",
      "weighted avg       0.87      0.85      0.84        59\n",
      "\n",
      "0.847457627118644\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "RandomOverSampler()\n",
      "SVC()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.60      0.65        30\n",
      "           1       0.65      0.76      0.70        29\n",
      "\n",
      "    accuracy                           0.68        59\n",
      "   macro avg       0.68      0.68      0.68        59\n",
      "weighted avg       0.68      0.68      0.68        59\n",
      "\n",
      "0.6779661016949152\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "RandomOverSampler()\n",
      "GradientBoostingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        33\n",
      "           1       1.00      0.96      0.98        26\n",
      "\n",
      "    accuracy                           0.98        59\n",
      "   macro avg       0.99      0.98      0.98        59\n",
      "weighted avg       0.98      0.98      0.98        59\n",
      "\n",
      "0.9830508474576272\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "RandomOverSampler()\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        34\n",
      "           1       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.98        59\n",
      "   macro avg       0.99      0.98      0.98        59\n",
      "weighted avg       0.98      0.98      0.98        59\n",
      "\n",
      "0.9830508474576272\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTE()\n",
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.91      0.83        32\n",
      "           1       0.86      0.67      0.75        27\n",
      "\n",
      "    accuracy                           0.80        59\n",
      "   macro avg       0.81      0.79      0.79        59\n",
      "weighted avg       0.81      0.80      0.79        59\n",
      "\n",
      "0.7966101694915254\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTE()\n",
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        27\n",
      "           1       0.91      0.91      0.91        32\n",
      "\n",
      "    accuracy                           0.90        59\n",
      "   macro avg       0.90      0.90      0.90        59\n",
      "weighted avg       0.90      0.90      0.90        59\n",
      "\n",
      "0.8983050847457628\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTE()\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73        23\n",
      "           1       1.00      0.53      0.69        36\n",
      "\n",
      "    accuracy                           0.71        59\n",
      "   macro avg       0.79      0.76      0.71        59\n",
      "weighted avg       0.83      0.71      0.71        59\n",
      "\n",
      "0.711864406779661\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTE()\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        31\n",
      "           1       0.96      0.96      0.96        28\n",
      "\n",
      "    accuracy                           0.97        59\n",
      "   macro avg       0.97      0.97      0.97        59\n",
      "weighted avg       0.97      0.97      0.97        59\n",
      "\n",
      "0.9661016949152542\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTE()\n",
      "KNeighborsClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.89      0.81        28\n",
      "           1       0.88      0.71      0.79        31\n",
      "\n",
      "    accuracy                           0.80        59\n",
      "   macro avg       0.81      0.80      0.80        59\n",
      "weighted avg       0.81      0.80      0.80        59\n",
      "\n",
      "0.7966101694915254\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTE()\n",
      "SVC()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.59      0.67        34\n",
      "           1       0.58      0.76      0.66        25\n",
      "\n",
      "    accuracy                           0.66        59\n",
      "   macro avg       0.67      0.67      0.66        59\n",
      "weighted avg       0.69      0.66      0.66        59\n",
      "\n",
      "0.6610169491525424\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTE()\n",
      "GradientBoostingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        26\n",
      "           1       0.97      0.97      0.97        33\n",
      "\n",
      "    accuracy                           0.97        59\n",
      "   macro avg       0.97      0.97      0.97        59\n",
      "weighted avg       0.97      0.97      0.97        59\n",
      "\n",
      "0.9661016949152542\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTE()\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       1.00      1.00      1.00        38\n",
      "\n",
      "    accuracy                           1.00        59\n",
      "   macro avg       1.00      1.00      1.00        59\n",
      "weighted avg       1.00      1.00      1.00        59\n",
      "\n",
      "1.0\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "ADASYN()\n",
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.83      0.81        29\n",
      "           1       0.83      0.80      0.81        30\n",
      "\n",
      "    accuracy                           0.81        59\n",
      "   macro avg       0.81      0.81      0.81        59\n",
      "weighted avg       0.81      0.81      0.81        59\n",
      "\n",
      "0.8135593220338984\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "ADASYN()\n",
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88        26\n",
      "           1       0.96      0.82      0.89        33\n",
      "\n",
      "    accuracy                           0.88        59\n",
      "   macro avg       0.89      0.89      0.88        59\n",
      "weighted avg       0.89      0.88      0.88        59\n",
      "\n",
      "0.8813559322033898\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "ADASYN()\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.91      0.74        23\n",
      "           1       0.92      0.64      0.75        36\n",
      "\n",
      "    accuracy                           0.75        59\n",
      "   macro avg       0.77      0.78      0.75        59\n",
      "weighted avg       0.80      0.75      0.75        59\n",
      "\n",
      "0.7457627118644068\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "ADASYN()\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        35\n",
      "           1       1.00      0.88      0.93        24\n",
      "\n",
      "    accuracy                           0.95        59\n",
      "   macro avg       0.96      0.94      0.95        59\n",
      "weighted avg       0.95      0.95      0.95        59\n",
      "\n",
      "0.9491525423728814\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "ADASYN()\n",
      "KNeighborsClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79        24\n",
      "           1       1.00      0.63      0.77        35\n",
      "\n",
      "    accuracy                           0.78        59\n",
      "   macro avg       0.82      0.81      0.78        59\n",
      "weighted avg       0.86      0.78      0.78        59\n",
      "\n",
      "0.7796610169491526\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "ADASYN()\n",
      "SVC()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.52      0.61        29\n",
      "           1       0.64      0.83      0.72        30\n",
      "\n",
      "    accuracy                           0.68        59\n",
      "   macro avg       0.70      0.68      0.67        59\n",
      "weighted avg       0.69      0.68      0.67        59\n",
      "\n",
      "0.6779661016949152\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "ADASYN()\n",
      "GradientBoostingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        29\n",
      "           1       1.00      0.93      0.97        30\n",
      "\n",
      "    accuracy                           0.97        59\n",
      "   macro avg       0.97      0.97      0.97        59\n",
      "weighted avg       0.97      0.97      0.97        59\n",
      "\n",
      "0.9661016949152542\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "ADASYN()\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        25\n",
      "           1       1.00      0.97      0.99        34\n",
      "\n",
      "    accuracy                           0.98        59\n",
      "   macro avg       0.98      0.99      0.98        59\n",
      "weighted avg       0.98      0.98      0.98        59\n",
      "\n",
      "0.9830508474576272\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "TomekLinks()\n",
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.45      0.56        11\n",
      "           1       0.81      0.93      0.86        27\n",
      "\n",
      "    accuracy                           0.79        38\n",
      "   macro avg       0.76      0.69      0.71        38\n",
      "weighted avg       0.78      0.79      0.77        38\n",
      "\n",
      "0.7894736842105263\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "TomekLinks()\n",
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.63        10\n",
      "           1       0.86      0.89      0.88        28\n",
      "\n",
      "    accuracy                           0.82        38\n",
      "   macro avg       0.76      0.75      0.75        38\n",
      "weighted avg       0.81      0.82      0.81        38\n",
      "\n",
      "0.8157894736842105\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "TomekLinks()\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.83      0.37         6\n",
      "           1       0.94      0.50      0.65        32\n",
      "\n",
      "    accuracy                           0.55        38\n",
      "   macro avg       0.59      0.67      0.51        38\n",
      "weighted avg       0.83      0.55      0.61        38\n",
      "\n",
      "0.5526315789473685\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "TomekLinks()\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82        12\n",
      "           1       0.89      0.96      0.93        26\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.90      0.86      0.87        38\n",
      "weighted avg       0.90      0.89      0.89        38\n",
      "\n",
      "0.8947368421052632\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "TomekLinks()\n",
      "KNeighborsClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.55      0.67        11\n",
      "           1       0.84      0.96      0.90        27\n",
      "\n",
      "    accuracy                           0.84        38\n",
      "   macro avg       0.85      0.75      0.78        38\n",
      "weighted avg       0.84      0.84      0.83        38\n",
      "\n",
      "0.8421052631578947\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "TomekLinks()\n",
      "SVC()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.08      0.14        13\n",
      "           1       0.68      1.00      0.81        25\n",
      "\n",
      "    accuracy                           0.68        38\n",
      "   macro avg       0.84      0.54      0.47        38\n",
      "weighted avg       0.79      0.68      0.58        38\n",
      "\n",
      "0.6842105263157895\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "TomekLinks()\n",
      "GradientBoostingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.89      0.80         9\n",
      "           1       0.96      0.90      0.93        29\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.85      0.89      0.86        38\n",
      "weighted avg       0.91      0.89      0.90        38\n",
      "\n",
      "0.8947368421052632\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "TomekLinks()\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00        34\n",
      "\n",
      "    accuracy                           1.00        38\n",
      "   macro avg       1.00      1.00      1.00        38\n",
      "weighted avg       1.00      1.00      1.00        38\n",
      "\n",
      "1.0\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "RandomUnderSampler()\n",
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        11\n",
      "           1       0.89      0.89      0.89         9\n",
      "\n",
      "    accuracy                           0.90        20\n",
      "   macro avg       0.90      0.90      0.90        20\n",
      "weighted avg       0.90      0.90      0.90        20\n",
      "\n",
      "0.9\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "RandomUnderSampler()\n",
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88        12\n",
      "           1       0.86      0.75      0.80         8\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.85      0.83      0.84        20\n",
      "weighted avg       0.85      0.85      0.85        20\n",
      "\n",
      "0.85\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "RandomUnderSampler()\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        12\n",
      "           1       1.00      0.50      0.67         8\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.88      0.75      0.76        20\n",
      "weighted avg       0.85      0.80      0.78        20\n",
      "\n",
      "0.8\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "RandomUnderSampler()\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        12\n",
      "           1       1.00      0.50      0.67         8\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.88      0.75      0.76        20\n",
      "weighted avg       0.85      0.80      0.78        20\n",
      "\n",
      "0.8\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "RandomUnderSampler()\n",
      "KNeighborsClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80         8\n",
      "           1       0.85      0.92      0.88        12\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.85      0.83      0.84        20\n",
      "weighted avg       0.85      0.85      0.85        20\n",
      "\n",
      "0.85\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "RandomUnderSampler()\n",
      "SVC()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.50      0.60        12\n",
      "           1       0.50      0.75      0.60         8\n",
      "\n",
      "    accuracy                           0.60        20\n",
      "   macro avg       0.62      0.62      0.60        20\n",
      "weighted avg       0.65      0.60      0.60        20\n",
      "\n",
      "0.6\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "RandomUnderSampler()\n",
      "GradientBoostingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.69      0.78        13\n",
      "           1       0.60      0.86      0.71         7\n",
      "\n",
      "    accuracy                           0.75        20\n",
      "   macro avg       0.75      0.77      0.74        20\n",
      "weighted avg       0.80      0.75      0.76        20\n",
      "\n",
      "0.75\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "RandomUnderSampler()\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         6\n",
      "           1       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.80        20\n",
      "   macro avg       0.76      0.76      0.76        20\n",
      "weighted avg       0.80      0.80      0.80        20\n",
      "\n",
      "0.8\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "EditedNearestNeighbours()\n",
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.63        10\n",
      "           1       0.83      0.86      0.84        22\n",
      "\n",
      "    accuracy                           0.78        32\n",
      "   macro avg       0.75      0.73      0.74        32\n",
      "weighted avg       0.78      0.78      0.78        32\n",
      "\n",
      "0.78125\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "EditedNearestNeighbours()\n",
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        11\n",
      "           1       0.95      0.95      0.95        21\n",
      "\n",
      "    accuracy                           0.94        32\n",
      "   macro avg       0.93      0.93      0.93        32\n",
      "weighted avg       0.94      0.94      0.94        32\n",
      "\n",
      "0.9375\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "EditedNearestNeighbours()\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      1.00      0.35         3\n",
      "           1       1.00      0.62      0.77        29\n",
      "\n",
      "    accuracy                           0.66        32\n",
      "   macro avg       0.61      0.81      0.56        32\n",
      "weighted avg       0.93      0.66      0.73        32\n",
      "\n",
      "0.65625\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "EditedNearestNeighbours()\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        10\n",
      "           1       0.92      1.00      0.96        22\n",
      "\n",
      "    accuracy                           0.94        32\n",
      "   macro avg       0.96      0.90      0.92        32\n",
      "weighted avg       0.94      0.94      0.94        32\n",
      "\n",
      "0.9375\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "EditedNearestNeighbours()\n",
      "KNeighborsClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89         9\n",
      "           1       0.96      0.96      0.96        23\n",
      "\n",
      "    accuracy                           0.94        32\n",
      "   macro avg       0.92      0.92      0.92        32\n",
      "weighted avg       0.94      0.94      0.94        32\n",
      "\n",
      "0.9375\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "EditedNearestNeighbours()\n",
      "SVC()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57        10\n",
      "           1       0.79      1.00      0.88        22\n",
      "\n",
      "    accuracy                           0.81        32\n",
      "   macro avg       0.89      0.70      0.73        32\n",
      "weighted avg       0.85      0.81      0.78        32\n",
      "\n",
      "0.8125\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "EditedNearestNeighbours()\n",
      "GradientBoostingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91         6\n",
      "           1       0.96      1.00      0.98        26\n",
      "\n",
      "    accuracy                           0.97        32\n",
      "   macro avg       0.98      0.92      0.95        32\n",
      "weighted avg       0.97      0.97      0.97        32\n",
      "\n",
      "0.96875\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "EditedNearestNeighbours()\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80         8\n",
      "           1       0.92      0.96      0.94        24\n",
      "\n",
      "    accuracy                           0.91        32\n",
      "   macro avg       0.89      0.85      0.87        32\n",
      "weighted avg       0.90      0.91      0.90        32\n",
      "\n",
      "0.90625\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTEENN()\n",
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.96      0.88        23\n",
      "           1       0.94      0.77      0.85        22\n",
      "\n",
      "    accuracy                           0.87        45\n",
      "   macro avg       0.88      0.86      0.86        45\n",
      "weighted avg       0.88      0.87      0.87        45\n",
      "\n",
      "0.8666666666666667\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTEENN()\n",
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       1.00      1.00      1.00        24\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "1.0\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTEENN()\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.89        27\n",
      "           1       1.00      0.63      0.77        19\n",
      "\n",
      "    accuracy                           0.85        46\n",
      "   macro avg       0.90      0.82      0.83        46\n",
      "weighted avg       0.88      0.85      0.84        46\n",
      "\n",
      "0.8478260869565217\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTEENN()\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        26\n",
      "\n",
      "    accuracy                           1.00        46\n",
      "   macro avg       1.00      1.00      1.00        46\n",
      "weighted avg       1.00      1.00      1.00        46\n",
      "\n",
      "1.0\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTEENN()\n",
      "KNeighborsClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        24\n",
      "           1       1.00      0.95      0.98        22\n",
      "\n",
      "    accuracy                           0.98        46\n",
      "   macro avg       0.98      0.98      0.98        46\n",
      "weighted avg       0.98      0.98      0.98        46\n",
      "\n",
      "0.9782608695652174\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTEENN()\n",
      "SVC()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.83      0.84        23\n",
      "           1       0.83      0.87      0.85        23\n",
      "\n",
      "    accuracy                           0.85        46\n",
      "   macro avg       0.85      0.85      0.85        46\n",
      "weighted avg       0.85      0.85      0.85        46\n",
      "\n",
      "0.8478260869565217\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTEENN()\n",
      "GradientBoostingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        29\n",
      "           1       1.00      1.00      1.00        16\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "1.0\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTEENN()\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        25\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "1.0\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTETomek()\n",
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.76      0.76        29\n",
      "           1       0.76      0.76      0.76        29\n",
      "\n",
      "    accuracy                           0.76        58\n",
      "   macro avg       0.76      0.76      0.76        58\n",
      "weighted avg       0.76      0.76      0.76        58\n",
      "\n",
      "0.7586206896551724\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTETomek()\n",
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89        32\n",
      "           1       0.86      0.89      0.87        27\n",
      "\n",
      "    accuracy                           0.88        59\n",
      "   macro avg       0.88      0.88      0.88        59\n",
      "weighted avg       0.88      0.88      0.88        59\n",
      "\n",
      "0.8813559322033898\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTETomek()\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.96      0.81        28\n",
      "           1       0.95      0.60      0.73        30\n",
      "\n",
      "    accuracy                           0.78        58\n",
      "   macro avg       0.82      0.78      0.77        58\n",
      "weighted avg       0.82      0.78      0.77        58\n",
      "\n",
      "0.7758620689655172\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTETomek()\n",
      "RandomForestClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88        28\n",
      "           1       0.90      0.87      0.89        31\n",
      "\n",
      "    accuracy                           0.88        59\n",
      "   macro avg       0.88      0.88      0.88        59\n",
      "weighted avg       0.88      0.88      0.88        59\n",
      "\n",
      "0.8813559322033898\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTETomek()\n",
      "KNeighborsClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.87        26\n",
      "           1       1.00      0.75      0.86        32\n",
      "\n",
      "    accuracy                           0.86        58\n",
      "   macro avg       0.88      0.88      0.86        58\n",
      "weighted avg       0.89      0.86      0.86        58\n",
      "\n",
      "0.8620689655172413\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTETomek()\n",
      "SVC()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.67      0.68        27\n",
      "           1       0.71      0.73      0.72        30\n",
      "\n",
      "    accuracy                           0.70        57\n",
      "   macro avg       0.70      0.70      0.70        57\n",
      "weighted avg       0.70      0.70      0.70        57\n",
      "\n",
      "0.7017543859649122\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTETomek()\n",
      "GradientBoostingClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        29\n",
      "           1       1.00      0.93      0.96        29\n",
      "\n",
      "    accuracy                           0.97        58\n",
      "   macro avg       0.97      0.97      0.97        58\n",
      "weighted avg       0.97      0.97      0.97        58\n",
      "\n",
      "0.9655172413793104\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "SMOTETomek()\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        29\n",
      "           1       0.96      0.93      0.95        29\n",
      "\n",
      "    accuracy                           0.95        58\n",
      "   macro avg       0.95      0.95      0.95        58\n",
      "weighted avg       0.95      0.95      0.95        58\n",
      "\n",
      "0.9482758620689655\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in resamplers:\n",
    "    for j in models:\n",
    "        X_new,y_new = i.fit_resample(X,y)\n",
    "        x_train,x_test,y_train,y_test = train_test_split(X_new,y_new,test_size=0.2)\n",
    "        model = j\n",
    "        model.fit(x_train,y_train)\n",
    "        pred = model.predict(x_test)\n",
    "        print('---'*20)\n",
    "        print(i)\n",
    "        print(j)\n",
    "        print(classification_report(y_test,pred))\n",
    "        print(accuracy_score(y_test,pred))\n",
    "        print('---'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1cdaece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTENN is having good results for random forest, gradiant boosting, Xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f42e22",
   "metadata": {},
   "source": [
    "# Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04efd895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTEENN()\n",
    "# RandomForestClassifier()\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00        20\n",
    "           1       1.00      1.00      1.00        26\n",
    "\n",
    "    accuracy                           1.00        46\n",
    "   macro avg       1.00      1.00      1.00        46\n",
    "weighted avg       1.00      1.00      1.00        46\n",
    "\n",
    "1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d92cf04",
   "metadata": {},
   "source": [
    "# Gradiant boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352a7232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTEENN()\n",
    "# GradientBoostingClassifier()\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00        29\n",
    "           1       1.00      1.00      1.00        16\n",
    "\n",
    "    accuracy                           1.00        45\n",
    "   macro avg       1.00      1.00      1.00        45\n",
    "weighted avg       1.00      1.00      1.00        45\n",
    "\n",
    "1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b346960",
   "metadata": {},
   "source": [
    "# XGB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39692c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTEENN()\n",
    "# XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "              colsample_bylevel=None, colsample_bynode=None,\n",
    "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
    "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
    "              gamma=None, grow_policy=None, importance_type=None,\n",
    "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
    "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
    "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
    "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
    "              num_parallel_tree=None, random_state=None, ...)\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       1.00      1.00      1.00        25\n",
    "           1       1.00      1.00      1.00        20\n",
    "\n",
    "    accuracy                           1.00        45\n",
    "   macro avg       1.00      1.00      1.00        45\n",
    "weighted avg       1.00      1.00      1.00        45\n",
    "\n",
    "1.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
